{"cells":[{"cell_type":"markdown","metadata":{},"source":["Jai shree ram"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T15:57:46.770457Z","iopub.status.busy":"2023-12-29T15:57:46.770134Z","iopub.status.idle":"2023-12-29T15:57:47.094231Z","shell.execute_reply":"2023-12-29T15:57:47.093094Z","shell.execute_reply.started":"2023-12-29T15:57:46.770430Z"},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import csv\n","import numpy as np\n","\n","def mapLabels(label:str):\n","    if label == \"boxing\":\n","        return 0\n","    elif label == \"drums\":\n","        return 1\n","    elif label == \"guitar\":\n","        return 2\n","    elif label == \"rowing\":\n","        return 3\n","    elif label == \"violin\":\n","        return 4\n","    \n","def removeConfidenceScore(keypoints):\n","    # Remove every kth item in-place\n","    K = 3\n","    del keypoints[K-1::3] \n","\n","    return keypoints\n","\n","    \n","\n","def removeKeypoints(keypoints):\n","    removeIdx = [0,1,4,7,8,9,11,12,14,15,16,17,18,19,20,22,23]\n","    removeIdx.reverse()\n","\n","    kp = np.array(keypoints).reshape(-1,3)\n","\n","    for idx in removeIdx:\n","        kp = np.delete(kp,idx,0)\n","    \n","    kp = kp.flatten()\n","\n","    return kp.tolist()\n","\n","    \n","def normalizeKeyPoints(keyPoints):\n","    poseKeyPoints = np.array(keyPoints).reshape(-1,3)\n","\n","    # Here we extracr x,y coordinates\n","    x_coordinates = poseKeyPoints[:, 0]\n","    y_coordinates = poseKeyPoints[:, 1]\n","\n","    x_coordinates_normalized = (x_coordinates - np.min(x_coordinates)) / (np.max(x_coordinates) - np.min(x_coordinates))\n","    y_coordinates_normalized = (y_coordinates - np.min(y_coordinates)) / (np.max(y_coordinates) - np.min(y_coordinates))\n","\n","    # Replace the normalized x, y coordinates in the original array\n","    poseKeyPoints[:, 0] = x_coordinates_normalized\n","    poseKeyPoints[:, 1] = y_coordinates_normalized\n","\n","    poseKeyPoints = poseKeyPoints.flatten()\n","\n","    return poseKeyPoints.tolist()\n","\n","\n","\n","def importData(dirPath:str):\n","    \"\"\"\n","    Returns the dataset as object from the 'dirPath'\n","    \"\"\"\n","\n","    trainSet = []\n","\n","    trainPath = dirPath + '/train/train/'\n","\n","    for file in os.listdir(trainPath):\n","        fileName = os.fsdecode(file)\n","\n","        # Extract label from file name\n","        label =  fileName.split(\"_\")[1].split(\".\")[0]\n","        # Here we map labeel to int \n","        y = mapLabels(label)\n","\n","        # Create a file object to parse csv files\n","        file = open(trainPath + fileName,newline='',encoding='utf-8')\n","        reader = csv.reader(file)\n","        samples = []\n","        \n","        # Extract 'keypoints, 'confidence' and 'angles'\n","        for row in reader:\n","            if len(row) == 79:\n","                keypoints = [float(row[i]) for i in range(0,75)]\n","                angles = [float(row[j]) for j in range(75,79)]\n","\n","                keypoints = removeKeypoints(keypoints)\n","\n","                poseKeypoints = normalizeKeyPoints(keypoints)\n","\n","                #Remove confidence score\n","                poseKeypoints =  removeConfidenceScore(poseKeypoints)\n","\n","                samples.append(poseKeypoints + angles)\n","        \n","        trainSet.append((samples,y))\n","    \n","    return trainSet\n","\n","def importTestData(dirPath:str):\n","    \"\"\"\n","    \"\"\"\n","\n","    testSet = []\n","\n","    testPath = dirPath + '/test/test/'\n","\n","    # Sort files\n","    fileList = sorted(os.listdir(testPath),key=lambda x:int(x.split('.')[0]))\n","\n","    for file in fileList:\n","        fileName = os.fsdecode(file)\n","\n","        # Extract label from file name\n","        id =  fileName.split(\".\")[0]\n","\n","        # Create a file object to parse csv files\n","        file = open(testPath + fileName,newline='',encoding='utf-8')\n","        reader = csv.reader(file)\n","        samples = []\n","        \n","        # Extract 'keypoints, confidence' and 'angles'\n","        for row in reader:\n","            if len(row) == 79:\n","                keypoints = [float(row[i]) for i in range(0,75)]\n","                angles = [float(row[j]) for j in range(75,79)]\n","                keypoints = removeKeypoints(keypoints)\n","                poseKeypoints = normalizeKeyPoints(keypoints)\n","\n","                #Remove confidence score\n","                poseKeypoints =  removeConfidenceScore(poseKeypoints)\n","\n","                samples.append(poseKeypoints + angles)\n","\n","        \n","        testSet.append((samples,id))\n","    \n","    return testSet\n","\n","def getDataDistribution(data):\n","    distribution = []\n","\n","    for d in data:\n","        sample = {'label':d[1],'count':len(d[0])}\n","        distribution.append(sample)\n","\n","    return distribution"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T17:23:43.732400Z","iopub.status.busy":"2023-12-29T17:23:43.731838Z","iopub.status.idle":"2023-12-29T18:14:27.909252Z","shell.execute_reply":"2023-12-29T18:14:27.907902Z","shell.execute_reply.started":"2023-12-29T17:23:43.732364Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional_7 (Bidirecti  (None, 10, 256)           152576    \n"," onal)                                                           \n","                                                                 \n"," dropout_5 (Dropout)         (None, 10, 256)           0         \n","                                                                 \n"," bidirectional_8 (Bidirecti  (None, 10, 256)           394240    \n"," onal)                                                           \n","                                                                 \n"," dropout_6 (Dropout)         (None, 10, 256)           0         \n","                                                                 \n"," bidirectional_9 (Bidirecti  (None, 256)               394240    \n"," onal)                                                           \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 957829 (3.65 MB)\n","Trainable params: 957829 (3.65 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","3953/3953 [==============================] - 300s 74ms/step - loss: 0.5745 - accuracy: 0.7871 - val_loss: 0.4355 - val_accuracy: 0.8476\n","Epoch 2/10\n","3953/3953 [==============================] - 288s 73ms/step - loss: 0.2852 - accuracy: 0.8975 - val_loss: 0.3323 - val_accuracy: 0.8915\n","Epoch 3/10\n","3953/3953 [==============================] - 288s 73ms/step - loss: 0.2090 - accuracy: 0.9245 - val_loss: 0.3155 - val_accuracy: 0.9065\n","Epoch 4/10\n","3953/3953 [==============================] - 289s 73ms/step - loss: 0.1672 - accuracy: 0.9392 - val_loss: 0.3300 - val_accuracy: 0.9070\n","Epoch 5/10\n","3953/3953 [==============================] - 290s 73ms/step - loss: 0.1387 - accuracy: 0.9494 - val_loss: 0.3742 - val_accuracy: 0.9107\n","Epoch 6/10\n","3953/3953 [==============================] - 292s 74ms/step - loss: 0.1207 - accuracy: 0.9557 - val_loss: 0.3536 - val_accuracy: 0.9150\n","Epoch 7/10\n","3953/3953 [==============================] - 296s 75ms/step - loss: 0.1070 - accuracy: 0.9610 - val_loss: 0.3283 - val_accuracy: 0.9213\n","Epoch 8/10\n","3953/3953 [==============================] - 297s 75ms/step - loss: 0.0948 - accuracy: 0.9653 - val_loss: 0.3235 - val_accuracy: 0.9270\n","Epoch 9/10\n","3953/3953 [==============================] - 294s 74ms/step - loss: 0.0869 - accuracy: 0.9687 - val_loss: 0.4241 - val_accuracy: 0.9165\n","Epoch 10/10\n","3953/3953 [==============================] - 294s 74ms/step - loss: 0.0795 - accuracy: 0.9714 - val_loss: 0.3459 - val_accuracy: 0.9312\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7b1fa28fe770>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["def create_sequences(data, time_steps=1):\n","    sequences = []\n","    labels = []\n","    for sample, label in data:\n","        for i in range(len(sample) - time_steps + 1):\n","            sequence = sample[i:(i + time_steps)]\n","            sequences.append(sequence)\n","            labels.append(label)\n","    return np.array(sequences), np.array(labels)\n","\n","time_steps = 10  \n","trainSet = importData(\"/kaggle/input/lsd-portfolio-3\")\n","X_train, y_train = create_sequences(trainSet, time_steps)\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n","\n","\n","feature_dim = X_train.shape[2]\n","\n","model = Sequential([\n","    Bidirectional(LSTM(128, return_sequences=True), input_shape=(time_steps, feature_dim)),\n","    Dropout(0.2),\n","    Bidirectional(LSTM(128, return_sequences=True)),\n","    Dropout(0.2),\n","    Bidirectional(LSTM(128)),\n","    Dense(64, activation='relu'),\n","    Dropout(0.5),\n","    Dense(5, activation='softmax')  # Assuming 5 classes based on your label mapping\n","])\n","\n","model.summary()\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T18:52:55.839259Z","iopub.status.busy":"2023-12-29T18:52:55.838915Z","iopub.status.idle":"2023-12-29T18:52:55.871404Z","shell.execute_reply":"2023-12-29T18:52:55.870220Z","shell.execute_reply.started":"2023-12-29T18:52:55.839230Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional_7 (Bidirecti  (None, 10, 256)           152576    \n"," onal)                                                           \n","                                                                 \n"," dropout_5 (Dropout)         (None, 10, 256)           0         \n","                                                                 \n"," bidirectional_8 (Bidirecti  (None, 10, 256)           394240    \n"," onal)                                                           \n","                                                                 \n"," dropout_6 (Dropout)         (None, 10, 256)           0         \n","                                                                 \n"," bidirectional_9 (Bidirecti  (None, 256)               394240    \n"," onal)                                                           \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 957829 (3.65 MB)\n","Trainable params: 957829 (3.65 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T18:53:40.472810Z","iopub.status.busy":"2023-12-29T18:53:40.472443Z","iopub.status.idle":"2023-12-29T18:54:03.479294Z","shell.execute_reply":"2023-12-29T18:54:03.478274Z","shell.execute_reply.started":"2023-12-29T18:53:40.472779Z"},"trusted":true},"outputs":[],"source":["def create_sequences_test(data, time_steps=1):\n","    sequences = []\n","    ids = []\n","    for sample, id in data:\n","        num_sequences = len(sample) - time_steps + 1\n","        for i in range(num_sequences):\n","            sequence = sample[i:(i + time_steps)]\n","            sequences.append(sequence)\n","            ids.append(id)  \n","    return np.array(sequences), ids\n","\n","testSet = importTestData(\"/kaggle/input/lsd-portfolio-3\")\n","X_test, test_ids = create_sequences_test(testSet, time_steps)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T18:54:03.483584Z","iopub.status.busy":"2023-12-29T18:54:03.483286Z","iopub.status.idle":"2023-12-29T18:55:00.324600Z","shell.execute_reply":"2023-12-29T18:55:00.323458Z","shell.execute_reply.started":"2023-12-29T18:54:03.483559Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3154/3154 [==============================] - 56s 18ms/step\n"]}],"source":["# Make predictions\n","predictions = model.predict(X_test)\n","\n","predicted_labels = np.argmax(predictions, axis=1)\n"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T18:55:00.326194Z","iopub.status.busy":"2023-12-29T18:55:00.325940Z","iopub.status.idle":"2023-12-29T18:55:00.445337Z","shell.execute_reply":"2023-12-29T18:55:00.444295Z","shell.execute_reply.started":"2023-12-29T18:55:00.326174Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Submission file created: submission11.csv\n"]}],"source":["\n","import csv\n","\n","predicted_labels = np.argmax(predictions, axis=1)\n","\n","submission_data = zip(test_ids, predicted_labels)\n","\n","# Create a submission file\n","submission_file = \"submission11.csv\"\n","with open(submission_file, 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"id\", \"action\"])\n","    for id, label in submission_data:\n","        writer.writerow([id, label])\n","\n","print(f\"Submission file created: {submission_file}\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["This is to run on the submission file generated....applies to everything"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T18:58:17.363318Z","iopub.status.busy":"2023-12-29T18:58:17.362979Z","iopub.status.idle":"2023-12-29T18:58:17.466986Z","shell.execute_reply":"2023-12-29T18:58:17.466076Z","shell.execute_reply.started":"2023-12-29T18:58:17.363294Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Final submission file created: submission_final.csv\n"]}],"source":["import csv\n","from collections import Counter\n","\n","# Load the predictions from the CSV file\n","file_path = '/kaggle/working/submission6.csv'\n","\n","predictions_by_id = {}\n","\n","with open(file_path, newline='') as csvfile:\n","    reader = csv.reader(csvfile)\n","    next(reader)  # Skip the header row\n","    for row in reader:\n","        id, prediction = int(row[0]), int(row[1])\n","        if id not in predictions_by_id:\n","            predictions_by_id[id] = []\n","        predictions_by_id[id].append(prediction)\n","\n","# Find the most common prediction for each ID\n","final_predictions = {id: Counter(preds).most_common(1)[0][0] for id, preds in predictions_by_id.items()}\n","\n","# Create a new submission file with these most common predictions\n","submission_file = 'submission_final.csv'\n","with open(submission_file, 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"id\", \"action\"])\n","    for id in range(305):  # Assuming IDs from 0 to 304\n","        writer.writerow([id, final_predictions.get(id, 0)])  # Default to 0 if no prediction\n","\n","print(f\"Final submission file created: {submission_file}\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6699530,"sourceId":61945,"sourceType":"competition"},{"datasetId":4217135,"sourceId":7274197,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
